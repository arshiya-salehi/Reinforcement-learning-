{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CS 175: Deep Reinforcement Learning AutoScaler vs. Kubernetes HPA\n",
        "\n",
        "This notebook demonstrates the comparison between RL-based autoscaling (DQN/PPO) and Kubernetes HPA-style rule-based autoscaling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports and Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import gymnasium as gym\n",
        "import gym_scaling\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add parent directory to path\n",
        "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
        "\n",
        "from src.env_wrapper import ScalingEnvWrapper\n",
        "from src.hpa_autoscaler import HPAAutoscaling\n",
        "from src.static_autoscaler import StaticAutoscaling\n",
        "from gym_scaling.envs.scaling_env import INPUTS\n",
        "from src.load_generators import LOAD_PATTERNS\n",
        "\n",
        "print(\"Setup complete!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Pre-trained Models (if available)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from stable_baselines3 import DQN, PPO\n",
        "\n",
        "models_dir = 'models'\n",
        "dqn_model = None\n",
        "ppo_model = None\n",
        "\n",
        "# Try to load DQN model\n",
        "dqn_path = os.path.join(models_dir, 'dqn_model.zip')\n",
        "if os.path.exists(dqn_path):\n",
        "    env_for_load = ScalingEnvWrapper(gym.make('gym_scaling/Scaling-v0'))\n",
        "    dqn_model = DQN.load(dqn_path, env=env_for_load)\n",
        "    env_for_load.close()\n",
        "    print(f\"Loaded DQN model from {dqn_path}\")\n",
        "else:\n",
        "    print(f\"DQN model not found at {dqn_path}\")\n",
        "\n",
        "# Try to load PPO model\n",
        "ppo_path = os.path.join(models_dir, 'ppo_model.zip')\n",
        "if os.path.exists(ppo_path):\n",
        "    env_for_load = ScalingEnvWrapper(gym.make('gym_scaling/Scaling-v0'))\n",
        "    ppo_model = PPO.load(ppo_path, env=env_for_load)\n",
        "    env_for_load.close()\n",
        "    print(f\"Loaded PPO model from {ppo_path}\")\n",
        "else:\n",
        "    print(f\"PPO model not found at {ppo_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Quick Demonstration\n",
        "\n",
        "Run a short episode to demonstrate the autoscaling behavior\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_episode_rl(env, model, max_steps=200):\n",
        "    \"\"\"Run a single episode with RL agent\"\"\"\n",
        "    obs = env.reset()\n",
        "    metrics = {'instances': [], 'queue_sizes': [], 'loads': [], 'total_cost': 0.0, 'total_reward': 0.0}\n",
        "    for step in range(max_steps):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, done, info = env.step(action)\n",
        "        metrics['instances'].append(len(env.instances))\n",
        "        metrics['queue_sizes'].append(env.queue_size)\n",
        "        metrics['loads'].append(env.load)\n",
        "        metrics['total_cost'] += env.total_cost\n",
        "        metrics['total_reward'] += reward\n",
        "        if done:\n",
        "            break\n",
        "    metrics['avg_queue_size'] = np.mean(metrics['queue_sizes'])\n",
        "    metrics['avg_load'] = np.mean(metrics['loads'])\n",
        "    metrics['avg_instances'] = np.mean(metrics['instances'])\n",
        "    return metrics\n",
        "\n",
        "def run_episode_hpa(env, max_steps=200):\n",
        "    \"\"\"Run a single episode with HPA autoscaler\"\"\"\n",
        "    env.scaling_env_options['input'] = INPUTS['SINE_CURVE']\n",
        "    autoscaler = HPAAutoscaling()\n",
        "    obs = env.reset()\n",
        "    autoscaler.reset()\n",
        "    metrics = {'instances': [], 'queue_sizes': [], 'loads': [], 'total_cost': 0.0, 'total_reward': 0.0}\n",
        "    for step in range(max_steps):\n",
        "        load = env.load\n",
        "        action = autoscaler.get_action(obs, load, step)\n",
        "        obs, reward, done, info = env.step(action)\n",
        "        metrics['instances'].append(len(env.instances))\n",
        "        metrics['queue_sizes'].append(env.queue_size)\n",
        "        metrics['loads'].append(env.load)\n",
        "        metrics['total_cost'] += env.total_cost\n",
        "        metrics['total_reward'] += reward\n",
        "        if done:\n",
        "            break\n",
        "    metrics['avg_queue_size'] = np.mean(metrics['queue_sizes'])\n",
        "    metrics['avg_load'] = np.mean(metrics['loads'])\n",
        "    metrics['avg_instances'] = np.mean(metrics['instances'])\n",
        "    return metrics\n",
        "\n",
        "# Run demonstration\n",
        "env = ScalingEnvWrapper(gym.make('gym_scaling/Scaling-v0'))\n",
        "env.change_rate = 10\n",
        "env.scaling_env_options['input'] = INPUTS['SINE_CURVE']\n",
        "\n",
        "hpa_metrics = run_episode_hpa(env, max_steps=200)\n",
        "print(\"HPA Results:\")\n",
        "print(f\"  Total Cost: {hpa_metrics['total_cost']:.2f}\")\n",
        "print(f\"  Avg Queue Size: {hpa_metrics['avg_queue_size']:.2f}\")\n",
        "print(f\"  Avg Instances: {hpa_metrics['avg_instances']:.2f}\\\n")\n",
        "\n",
        "if dqn_model is not None:\n",
        "    dqn_metrics = run_episode_rl(env, dqn_model, max_steps=200)\n",
        "    print(\"DQN Results:\")\n",
        "    print(f\"  Total Cost: {dqn_metrics['total_cost']:.2f}\")\n",
        "    print(f\"  Avg Queue Size: {dqn_metrics['avg_queue_size']:.2f}\")\n",
        "    print(f\"  Avg Instances: {dqn_metrics['avg_instances']:.2f}\\\n")\n",
        "\n",
        "if ppo_model is not None:\n",
        "    ppo_metrics = run_episode_rl(env, ppo_model, max_steps=200)\n",
        "    print(\"PPO Results:\")\n",
        "    print(f\"  Total Cost: {ppo_metrics['total_cost']:.2f}\")\n",
        "    print(f\"  Avg Queue Size: {ppo_metrics['avg_queue_size']:.2f}\")\n",
        "    print(f\"  Avg Instances: {ppo_metrics['avg_instances']:.2f}\\\n")\n",
        "\n",
        "env.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualization: Scaling Curves Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Instances over time\n",
        "ax1 = axes[0, 0]\n",
        "ax1.plot(hpa_metrics['instances'], label='HPA', alpha=0.7)\n",
        "if dqn_model is not None:\n",
        "    ax1.plot(dqn_metrics['instances'], label='DQN', alpha=0.7)\n",
        "if ppo_model is not None:\n",
        "    ax1.plot(ppo_metrics['instances'], label='PPO', alpha=0.7)\n",
        "ax1.set_xlabel('Step')\n",
        "ax1.set_ylabel('Number of Instances')\n",
        "ax1.set_title('Scaling Behavior: Instances Over Time')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Queue sizes\n",
        "ax2 = axes[0, 1]\n",
        "ax2.plot(hpa_metrics['queue_sizes'], label='HPA', alpha=0.7)\n",
        "if dqn_model is not None:\n",
        "    ax2.plot(dqn_metrics['queue_sizes'], label='DQN', alpha=0.7)\n",
        "if ppo_model is not None:\n",
        "    ax2.plot(ppo_metrics['queue_sizes'], label='PPO', alpha=0.7)\n",
        "ax2.set_xlabel('Step')\n",
        "ax2.set_ylabel('Queue Size')\n",
        "ax2.set_title('Queue Size Over Time')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Load percentages\n",
        "ax3 = axes[1, 0]\n",
        "ax3.plot(hpa_metrics['loads'], label='HPA', alpha=0.7)\n",
        "if dqn_model is not None:\n",
        "    ax3.plot(dqn_metrics['loads'], label='DQN', alpha=0.7)\n",
        "if ppo_model is not None:\n",
        "    ax3.plot(ppo_metrics['loads'], label='PPO', alpha=0.7)\n",
        "ax3.set_xlabel('Step')\n",
        "ax3.set_ylabel('Load (%)')\n",
        "ax3.set_title('Load Over Time')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Cost comparison\n",
        "ax4 = axes[1, 1]\n",
        "methods = ['HPA']\n",
        "costs = [hpa_metrics['total_cost']]\n",
        "if dqn_model is not None:\n",
        "    methods.append('DQN')\n",
        "    costs.append(dqn_metrics['total_cost'])\n",
        "if ppo_model is not None:\n",
        "    methods.append('PPO')\n",
        "    costs.append(ppo_metrics['total_cost'])\n",
        "ax4.bar(methods, costs, alpha=0.7)\n",
        "ax4.set_ylabel('Total Cost')\n",
        "ax4.set_title('Cost Comparison')\n",
        "ax4.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(\"Visualization complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}